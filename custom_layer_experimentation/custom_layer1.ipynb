{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomActivation(tf.keras.layers.Dense):\n",
    "    def __init__(self, units=32, input_shape=[1]):\n",
    "      super(RandomActivation, self).__init__(units=units, input_shape=input_shape)\n",
    "      self.units = units\n",
    "\n",
    "    def print_tensor(self, tensor):\n",
    "       for i in tensor:\n",
    "          print(i)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        print(inputs)\n",
    "        if training:\n",
    "          print(\"training\")\n",
    "          return tf.matmul(inputs, self.kernel) \n",
    "        else:\n",
    "          print(\"not training\")\n",
    "          #randomize the order\n",
    "          if inputs is not None:  # condition solves the case when call is called in model.compile with inputs=None\n",
    "            indices = random.sample(range(self.units), self.units)\n",
    "            #tmp_kernel = tf.gather(self.kernel, indices, axis=-1)\n",
    "            tmp_kernel = self.kernel\n",
    "            print(self.kernel)\n",
    "            print(tmp_kernel)\n",
    "            print(tf.matmul(inputs, self.kernel))\n",
    "            print(tf.matmul(inputs, tmp_kernel))\n",
    "            #choice = random.choice([0,1])\n",
    "            #if choice == 0:\n",
    "            #  return tf.matmul(inputs, self.kernel)\n",
    "            #else:\n",
    "            #  return tf.matmul(inputs, tmp_kernel)\n",
    "          return tf.matmul(inputs, self.kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_activation_80_input:0\", shape=(None, 1), dtype=float32)\n",
      "not training\n",
      "<tf.Variable 'random_activation_80/kernel:0' shape=(1, 10) dtype=float32>\n",
      "Tensor(\"random_activation_80/GatherV2:0\", shape=(1, 10), dtype=float32)\n",
      "Tensor(\"random_activation_80/MatMul:0\", shape=(None, 10), dtype=float32)\n",
      "Tensor(\"random_activation_80/MatMul_1:0\", shape=(None, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([RandomActivation(units=10, input_shape=[1])])\n",
    "model.compile(optimizer=\"sgd\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (6, 1) was passed for an output of shape (None, 10) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[288], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(xs, ys)\n",
      "File \u001b[1;32mc:\\Users\\Leonard\\anaconda3\\envs\\dp_nn_env\\lib\\site-packages\\keras\\engine\\training_v1.py:854\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_call_args(\u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    853\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m--> 854\u001b[0m \u001b[39mreturn\u001b[39;00m func\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    855\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    856\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    857\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    858\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    859\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m    860\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    861\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    862\u001b[0m     validation_split\u001b[39m=\u001b[39;49mvalidation_split,\n\u001b[0;32m    863\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m    864\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m    865\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m    866\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    867\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m    868\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m    869\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m    870\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m    871\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m    872\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m    873\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m    874\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Leonard\\anaconda3\\envs\\dp_nn_env\\lib\\site-packages\\keras\\engine\\training_arrays_v1.py:698\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[0;32m    675\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    676\u001b[0m     model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    693\u001b[0m ):\n\u001b[0;32m    694\u001b[0m     batch_size \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39m_validate_or_infer_batch_size(\n\u001b[0;32m    695\u001b[0m         batch_size, steps_per_epoch, x\n\u001b[0;32m    696\u001b[0m     )\n\u001b[1;32m--> 698\u001b[0m     x, y, sample_weights \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49m_standardize_user_data(\n\u001b[0;32m    699\u001b[0m         x,\n\u001b[0;32m    700\u001b[0m         y,\n\u001b[0;32m    701\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    702\u001b[0m         class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m    703\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    704\u001b[0m         check_steps\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    705\u001b[0m         steps_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msteps_per_epoch\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    706\u001b[0m         steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m    707\u001b[0m         validation_split\u001b[39m=\u001b[39;49mvalidation_split,\n\u001b[0;32m    708\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m    709\u001b[0m     )\n\u001b[0;32m    711\u001b[0m     \u001b[39mif\u001b[39;00m validation_data:\n\u001b[0;32m    712\u001b[0m         val_x, val_y, val_sample_weights \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39m_prepare_validation_data(\n\u001b[0;32m    713\u001b[0m             validation_data, batch_size, validation_steps\n\u001b[0;32m    714\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Leonard\\anaconda3\\envs\\dp_nn_env\\lib\\site-packages\\keras\\engine\\training_v1.py:2650\u001b[0m, in \u001b[0;36mModel._standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2641\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   2642\u001b[0m     \u001b[39mnot\u001b[39;00m run_eagerly\n\u001b[0;32m   2643\u001b[0m     \u001b[39mand\u001b[39;00m is_build_called\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2646\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(_is_symbolic_tensor(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m all_inputs)\n\u001b[0;32m   2647\u001b[0m ):\n\u001b[0;32m   2648\u001b[0m     \u001b[39mreturn\u001b[39;00m [], [], \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2650\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_standardize_tensors(\n\u001b[0;32m   2651\u001b[0m     x,\n\u001b[0;32m   2652\u001b[0m     y,\n\u001b[0;32m   2653\u001b[0m     sample_weight,\n\u001b[0;32m   2654\u001b[0m     run_eagerly\u001b[39m=\u001b[39;49mrun_eagerly,\n\u001b[0;32m   2655\u001b[0m     dict_inputs\u001b[39m=\u001b[39;49mdict_inputs,\n\u001b[0;32m   2656\u001b[0m     is_dataset\u001b[39m=\u001b[39;49mis_dataset,\n\u001b[0;32m   2657\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   2658\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   2659\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Leonard\\anaconda3\\envs\\dp_nn_env\\lib\\site-packages\\keras\\engine\\training_v1.py:2781\u001b[0m, in \u001b[0;36mModel._standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2777\u001b[0m         training_utils_v1\u001b[39m.\u001b[39mcheck_array_lengths(x, y, sample_weights)\n\u001b[0;32m   2778\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_graph_network \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m run_eagerly:\n\u001b[0;32m   2779\u001b[0m             \u001b[39m# Additional checks to avoid users mistakenly using improper\u001b[39;00m\n\u001b[0;32m   2780\u001b[0m             \u001b[39m# loss fns.\u001b[39;00m\n\u001b[1;32m-> 2781\u001b[0m             training_utils_v1\u001b[39m.\u001b[39;49mcheck_loss_and_target_compatibility(\n\u001b[0;32m   2782\u001b[0m                 y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feed_loss_fns, feed_output_shapes\n\u001b[0;32m   2783\u001b[0m             )\n\u001b[0;32m   2785\u001b[0m     sample_weights, _, _ \u001b[39m=\u001b[39m training_utils\u001b[39m.\u001b[39mhandle_partial_sample_weights(\n\u001b[0;32m   2786\u001b[0m         y, sample_weights, feed_sample_weight_modes, check_all_flat\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2787\u001b[0m     )\n\u001b[0;32m   2788\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Leonard\\anaconda3\\envs\\dp_nn_env\\lib\\site-packages\\keras\\engine\\training_utils_v1.py:945\u001b[0m, in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[1;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[0;32m    943\u001b[0m     loss_type \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mfn \u001b[39mif\u001b[39;00m is_loss_wrapper \u001b[39melse\u001b[39;00m \u001b[39mtype\u001b[39m(loss)\n\u001b[0;32m    944\u001b[0m     loss_name \u001b[39m=\u001b[39m loss_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m--> 945\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    946\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mA target array with shape \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    947\u001b[0m     \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(y\u001b[39m.\u001b[39mshape)\n\u001b[0;32m    948\u001b[0m     \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m was passed for an output of shape \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    949\u001b[0m     \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(shape)\n\u001b[0;32m    950\u001b[0m     \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m while using as loss `\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    951\u001b[0m     \u001b[39m+\u001b[39m loss_name\n\u001b[0;32m    952\u001b[0m     \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mThis loss expects targets to have the same shape \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    954\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mas the output.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: A target array with shape (6, 1) was passed for an output of shape (None, 10) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "model.fit(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.4940248,  5.010808 , -7.2145033,  5.909131 ,  4.0233417,\n",
       "         1.0144997,  5.765031 ,  3.3395   ,  3.7291412, -5.4003453]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([10.0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp_nn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41ea5e9b777f8645252874eaefd35016a62d6c7634ad06ad60b3d12a86cf7869"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
